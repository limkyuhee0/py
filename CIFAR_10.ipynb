{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CIFAR_10.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "private_outputs": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/limkyuhee0/py/blob/master/CIFAR_10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CIFAR-10 Classification\n",
        "> I chose to use Greedy Algorithm over GridSearchCV algorithm for CIFAR-10 Image Classification. GridSearchCV might result in better performance but I believe it does not take much advantage of using GPU, and the time cost is higher than the advantage of convenience and accuracy. Therefore, I chose Greedy Algorithm for parameter settings. Given the range of values for a parameter, value that results in the best performance is chosen. The next parameter is chosen, assuming the value of the previously decided parameter as default. This process is done with 6 parameters, containing hyper-parameters."
      ],
      "metadata": {
        "id": "8REwd3xRpChl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "from tensorflow.keras.layers import Dropout\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "ZMcCLZI8C3s1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Data & Check first 15 Pictures"
      ],
      "metadata": {
        "id": "6wjzDcOmEttg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(X_train, y_train), (X_test, y_test) = datasets.cifar10.load_data()"
      ],
      "metadata": {
        "id": "zhAXWoDMEIZs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "for i in range(25):\n",
        "    plt.subplot(5,5,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(X_train[i])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "gKCVxmqbEJtf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train.reshape((50000, 32, 32, 3,1))\n",
        "X_test = X_test.reshape((10000, 32, 32, 3,1))\n",
        "X_train , X_test = X_train/255, X_test/255"
      ],
      "metadata": {
        "id": "JS55MbBiE-QY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training Models"
      ],
      "metadata": {
        "id": "LEpGasK5Gbw7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.Sequential()\n",
        "\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "hist = model.fit(X_train, y_train, epochs=10,batch_size=100, validation_data=(X_test,y_test))"
      ],
      "metadata": {
        "id": "_PH7nlGLC9gS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "plt.figure(figsize=(20,10))\n",
        "plt.plot(hist.history['val_accuracy'],label = 'test accuracy')\n",
        "plt.plot(hist.history['accuracy'],label = 'train accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "R8sYafrpF177"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dropout Dependencies"
      ],
      "metadata": {
        "id": "n7BTIHiSGrC6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dropouts = [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\n",
        "test_acc=[]\n",
        "for dropout in dropouts:\n",
        "    print('Dropout : ',(dropout))\n",
        "    model = models.Sequential()\n",
        "\n",
        "    model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
        "    model.add(Dropout(dropout))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "\n",
        "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "    model.add(Dropout(dropout))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "    model.add(Dropout(dropout))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(64, activation='relu'))\n",
        "    model.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "    model.summary()\n",
        "\n",
        "    model.compile(optimizer='adam',\n",
        "                loss='sparse_categorical_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "    hist = model.fit(X_train, y_train, epochs=10,batch_size=100)\n",
        "    loss,accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
        "    test_acc.append(accuracy)"
      ],
      "metadata": {
        "id": "gcHoXsnSGpk9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(20,10))\n",
        "plt.plot(dropouts, test_acc)\n",
        "plt.xlabel('Dropout')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Dropout Decision')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "zqhfnJttH6_N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Therefore, drop out is set to 0.2 further on."
      ],
      "metadata": {
        "id": "tZnKqDaUIrqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Batch Size Dependencies"
      ],
      "metadata": {
        "id": "o_L0G9s_IOI4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_sizes = [50,100,200,500,1000]\n",
        "dropout = 0.2\n",
        "test_acc=[]\n",
        "for batch_size in batch_sizes:\n",
        "    print('batch_size : ',(batch_size))\n",
        "    model = models.Sequential()\n",
        "\n",
        "    model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
        "    model.add(Dropout(dropout))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "\n",
        "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "    model.add(Dropout(dropout))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "    model.add(Dropout(dropout))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(64, activation='relu'))\n",
        "    model.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "    model.summary()\n",
        "\n",
        "    model.compile(optimizer='adam',\n",
        "                loss='sparse_categorical_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "    hist = model.fit(X_train, y_train, epochs=10,batch_size=batch_size)\n",
        "    score, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
        "    test_acc.append(accuracy)"
      ],
      "metadata": {
        "id": "7sXf2SUbINVn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(20,10))\n",
        "plt.plot(batch_sizes, test_acc)\n",
        "plt.xlabel('Batch Size')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Batch Size Decision')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "cydQL6wjKEzk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Therefore, batch size is set to 50 further on."
      ],
      "metadata": {
        "id": "NBjrnk_5LWOT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Kerner Initializer"
      ],
      "metadata": {
        "id": "L5s84zayJBZF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "initializers = [tf.keras.initializers.Constant(3.),#Constant\n",
        "                tf.keras.initializers.VarianceScaling(scale=1.0, mode=\"fan_in\", distribution=\"truncated_normal\", seed=None),#VarianceScaling\n",
        "                tf.keras.initializers.VarianceScaling(scale=0.1, mode='fan_in', distribution='uniform'),#VarianceScaling\n",
        "                tf.keras.initializers.GlorotNormal(),#GlorotNormal\n",
        "                tf.keras.initializers.GlorotUniform(),#GlorotUniform\n",
        "                tf.keras.initializers.HeNormal(),#HeNormal\n",
        "                tf.keras.initializers.HeUniform(),#HeUniform\n",
        "                tf.keras.initializers.Orthogonal()]#Orthogonal\n",
        "batch_size = 50\n",
        "dropout = 0.2\n",
        "test_acc=[]\n",
        "for initializer in initializers:\n",
        "    print('initializer : ',(initializer))\n",
        "    model = models.Sequential()\n",
        "\n",
        "    model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3),kernel_initializer = initializer))\n",
        "    model.add(Dropout(dropout))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "\n",
        "    model.add(layers.Conv2D(64, (3, 3), activation='relu',kernel_initializer = initializer))\n",
        "    model.add(Dropout(dropout))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "    model.add(layers.Conv2D(64, (3, 3), activation='relu',kernel_initializer = initializer))\n",
        "    model.add(Dropout(dropout))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(64, activation='relu',kernel_initializer = initializer))\n",
        "    model.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "    # model.summary()\n",
        "\n",
        "    model.compile(optimizer='adam',\n",
        "                loss='sparse_categorical_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "    hist = model.fit(X_train, y_train, epochs=10,batch_size=batch_size)\n",
        "    score, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
        "    test_acc.append(accuracy)"
      ],
      "metadata": {
        "id": "k0Mg40qwKQdY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "P5cWs8mNi_3r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(20,10))\n",
        "plt.plot(test_acc)\n",
        "plt.xlabel('Initializers')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Initializers Decision')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6i6GLrCMJD4L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Therefore, \"tf.keras.initializers.GlorotNormal()\" kernel initializer is used further on"
      ],
      "metadata": {
        "id": "YVvT5nnsj6tm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Padding"
      ],
      "metadata": {
        "id": "zr7MHU-XKjPC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "paddings = ['valid','same']\n",
        "initializer = tf.keras.initializers.GlorotNormal()\n",
        "batch_size = 50\n",
        "dropout = 0.2\n",
        "test_acc=[]\n",
        "for padding in paddings:\n",
        "    print('padding : ',padding)\n",
        "    model = models.Sequential()\n",
        "\n",
        "    model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3),kernel_initializer = initializer))\n",
        "    model.add(Dropout(dropout))\n",
        "    model.add(layers.MaxPooling2D((2, 2),padding = padding))\n",
        "\n",
        "\n",
        "    model.add(layers.Conv2D(64, (3, 3), activation='relu',kernel_initializer = initializer))\n",
        "    model.add(Dropout(dropout))\n",
        "    model.add(layers.MaxPooling2D((2, 2),padding = padding))\n",
        "\n",
        "    model.add(layers.Conv2D(64, (3, 3), activation='relu',kernel_initializer = initializer))\n",
        "    model.add(Dropout(dropout))\n",
        "    model.add(layers.MaxPooling2D((2, 2),padding = padding))\n",
        "\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(64, activation='relu',kernel_initializer = initializer))\n",
        "    model.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "    # model.summary()\n",
        "\n",
        "    model.compile(optimizer='adam',\n",
        "                loss='sparse_categorical_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "    hist = model.fit(X_train, y_train, epochs=10,batch_size=batch_size)\n",
        "    score, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
        "    test_acc.append(accuracy)"
      ],
      "metadata": {
        "id": "bp0Na21HKkxZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(20,10))\n",
        "plt.bar(paddings, test_acc)\n",
        "plt.xlabel('Paddings')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Paddings Decision')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "63K4H6hPWE-E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Therefore, padding is set to \"same\" further on."
      ],
      "metadata": {
        "id": "8fLP42orpdCv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Neurons\n"
      ],
      "metadata": {
        "id": "g7HXwxovJEkj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "neurons = [[32,64,64,64],\n",
        "           [32,64,128,32],\n",
        "           [16,32,64,128]]\n",
        "padding = \"same\"\n",
        "initializer = tf.keras.initializers.HeUniform()\n",
        "batch_size = 50\n",
        "dropout = 0.2\n",
        "test_acc=[]\n",
        "for neuron in neurons:\n",
        "    print('neuron : ',neuron)\n",
        "    model = models.Sequential()\n",
        "\n",
        "    model.add(layers.Conv2D(neuron[0], (3, 3), activation='relu', input_shape=(32, 32, 3),kernel_initializer = initializer))\n",
        "    model.add(Dropout(dropout))\n",
        "    model.add(layers.MaxPooling2D((2, 2),padding = padding))\n",
        "\n",
        "\n",
        "    model.add(layers.Conv2D(neuron[1], (3, 3), activation='relu',kernel_initializer = initializer))\n",
        "    model.add(Dropout(dropout))\n",
        "    model.add(layers.MaxPooling2D((2, 2),padding = padding))\n",
        "\n",
        "    model.add(layers.Conv2D(neuron[2], (3, 3), activation='relu',kernel_initializer = initializer))\n",
        "    model.add(Dropout(dropout))\n",
        "    model.add(layers.MaxPooling2D((2, 2),padding = padding))\n",
        "\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(neuron[3], activation='relu',kernel_initializer = initializer))\n",
        "    model.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "    # model.summary()\n",
        "\n",
        "    model.compile(optimizer='adam',\n",
        "                loss='sparse_categorical_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "    hist = model.fit(X_train, y_train, epochs=10,batch_size=batch_size)\n",
        "    score, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
        "    test_acc.append(accuracy)"
      ],
      "metadata": {
        "id": "mgM-aODmJQZF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(20,10))\n",
        "plt.plot(test_acc)\n",
        "plt.xlabel('Neurons')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Neurons Decision')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8DqboCcuWMsk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Therefore, neurons for each layer is set to [32,64,128,32] further on."
      ],
      "metadata": {
        "id": "O5MR-Pf_toTl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Epochs"
      ],
      "metadata": {
        "id": "aIrLPmwQWNJd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs=[10,20,50,100,200]\n",
        "neuron = [32,64,128,32]\n",
        "padding = \"same\"\n",
        "initializer = tf.keras.initializers.HeUniform()\n",
        "batch_size = 50\n",
        "dropout = 0.2\n",
        "test_acc=[]\n",
        "for epoch in epochs:\n",
        "    print('epoch : ',epoch)\n",
        "    model = models.Sequential()\n",
        "\n",
        "    model.add(layers.Conv2D(neuron[0], (3, 3), activation='relu', input_shape=(32, 32, 3),kernel_initializer = initializer))\n",
        "    model.add(Dropout(dropout))\n",
        "    model.add(layers.MaxPooling2D((2, 2),padding = padding))\n",
        "\n",
        "\n",
        "    model.add(layers.Conv2D(neuron[1], (3, 3), activation='relu',kernel_initializer = initializer))\n",
        "    model.add(Dropout(dropout))\n",
        "    model.add(layers.MaxPooling2D((2, 2),padding = padding))\n",
        "\n",
        "    model.add(layers.Conv2D(neuron[2], (3, 3), activation='relu',kernel_initializer = initializer))\n",
        "    model.add(Dropout(dropout))\n",
        "    model.add(layers.MaxPooling2D((2, 2),padding = padding))\n",
        "\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(neuron[3], activation='relu',kernel_initializer = initializer))\n",
        "    model.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "    # model.summary()\n",
        "\n",
        "    model.compile(optimizer='adam',\n",
        "                loss='sparse_categorical_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "    hist = model.fit(X_train, y_train, epochs=epoch,batch_size=batch_size)\n",
        "    score, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
        "    test_acc.append(accuracy)"
      ],
      "metadata": {
        "id": "w5oRnNS9WO06"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(20,10))\n",
        "plt.plot(epochs, test_acc)\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Epochs Decision')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "print('Best Performance : ',max(test_acc))"
      ],
      "metadata": {
        "id": "9f0OmEV4se8m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Therefore, the best performance is 76.7% accuracy."
      ],
      "metadata": {
        "id": "cf9gX6451V9a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(X_train, y_train), (X_test, y_test) = datasets.cifar10.load_data()\n",
        "\n",
        "X_train, X_val, y_train, y_val= train_test_split(X_train, y_train, test_size = 0.1)\n",
        "\n",
        "X_train = X_train.reshape((45000, 32, 32, 3,1))\n",
        "X_val = X_val.reshape((5000, 32, 32, 3,1))\n",
        "X_test = X_test.reshape((10000, 32, 32, 3,1))\n",
        "X_train , X_val, X_test = X_train/255, X_val/255, X_test/255"
      ],
      "metadata": {
        "id": "2yvzJsCxutpU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# More Complicated CNNS with Validation"
      ],
      "metadata": {
        "id": "OAIdjrmQxnhJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dropout Dependencies"
      ],
      "metadata": {
        "id": "IihMybSNuIqB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dropouts = [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\n",
        "test_acc=[]\n",
        "for dropout in dropouts:\n",
        "    print('Dropout : ',(dropout))\n",
        "    \n",
        "    model = models.Sequential()\n",
        "\n",
        "    model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
        "    model.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
        "    model.add(Dropout(dropout))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "    model.add(Dropout(dropout))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "    model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "    model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "    model.add(Dropout(dropout))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(32, activation='relu'))\n",
        "    model.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "    # model.summary()\n",
        "\n",
        "    model.compile(optimizer='adam',\n",
        "                loss='sparse_categorical_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "    hist = model.fit(X_train, y_train, epochs=10,batch_size=100,validation_data = (X_val, y_val))\n",
        "    loss,accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
        "    test_acc.append(accuracy)"
      ],
      "metadata": {
        "id": "Tz_yHEeSuIqC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(20,10))\n",
        "plt.plot(dropouts, test_acc)\n",
        "plt.xlabel('Dropout')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Dropout Decision')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "psho7-wUuIqD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Therefore, drop out is set to 0.2 further on."
      ],
      "metadata": {
        "id": "LGWONJuSuIqE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Batch Size Dependencies"
      ],
      "metadata": {
        "id": "tnrCzPpbuIqE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_sizes = [50,100,200,500,1000]\n",
        "dropout = 0.2\n",
        "test_acc=[]\n",
        "for batch_size in batch_sizes:\n",
        "    print('batch_size : ',(batch_size))\n",
        "    \n",
        "    model = models.Sequential()\n",
        "\n",
        "    model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
        "    model.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
        "    model.add(Dropout(dropout))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "    model.add(Dropout(dropout))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "    model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "    model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "    model.add(Dropout(dropout))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(32, activation='relu'))\n",
        "    model.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "    # model.summary()\n",
        "\n",
        "    model.compile(optimizer='adam',\n",
        "                loss='sparse_categorical_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "    hist = model.fit(X_train, y_train, epochs=10,batch_size=batch_size,validation_data = (X_val, y_val))\n",
        "    loss,accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
        "    test_acc.append(accuracy)"
      ],
      "metadata": {
        "id": "z4l6oQYSuIqE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(20,10))\n",
        "plt.plot(batch_sizes, test_acc)\n",
        "plt.xlabel('Batch Size')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Batch Size Decision')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "uiFC0OoduIqF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Therefore, batch size is set to 50 further on."
      ],
      "metadata": {
        "id": "Jk2oHCAnuIqF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Kerner Initializer"
      ],
      "metadata": {
        "id": "9DFXdUkwuIqF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "initializers = [tf.keras.initializers.VarianceScaling(scale=1.0, mode=\"fan_in\", distribution=\"truncated_normal\", seed=None),#VarianceScaling\n",
        "                tf.keras.initializers.VarianceScaling(scale=0.1, mode='fan_in', distribution='uniform'),#VarianceScaling\n",
        "                tf.keras.initializers.GlorotNormal(),#GlorotNormal\n",
        "                tf.keras.initializers.GlorotUniform(),#GlorotUniform\n",
        "                tf.keras.initializers.HeNormal(),#HeNormal\n",
        "                tf.keras.initializers.HeUniform(),#HeUniform\n",
        "batch_size = 50\n",
        "dropout = 0.2\n",
        "test_acc=[]\n",
        "for initializer in initializers:\n",
        "    print('initializer : ',(initializer))  \n",
        "    model = models.Sequential()\n",
        "\n",
        "    model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3),kernel_initializer = initializer))\n",
        "    model.add(layers.Conv2D(32, (3, 3), activation='relu',kernel_initializer = initializer))\n",
        "    model.add(Dropout(dropout))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "    model.add(layers.Conv2D(64, (3, 3), activation='relu',kernel_initializer = initializer))\n",
        "    model.add(layers.Conv2D(64, (3, 3), activation='relu',kernel_initializer = initializer))\n",
        "    model.add(Dropout(dropout))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "    model.add(layers.Conv2D(128, (3, 3), activation='relu',kernel_initializer = initializer))\n",
        "    model.add(layers.Conv2D(128, (3, 3), activation='relu',kernel_initializer = initializer))\n",
        "    model.add(Dropout(dropout))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(32, activation='relu',kernel_initializer = initializer))\n",
        "    model.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "    # model.summary()\n",
        "\n",
        "    model.compile(optimizer='adam',\n",
        "                loss='sparse_categorical_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "    hist = model.fit(X_train, y_train, epochs=10,batch_size=batch_size,validation_data = (X_val, y_val))\n",
        "    loss,accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
        "    test_acc.append(accuracy)"
      ],
      "metadata": {
        "id": "WYOIc4b4uIqG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(20,10))\n",
        "plt.plot(test_acc)\n",
        "plt.xlabel('Initializers')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Initializers Decision')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-7ZoL0NZuIqG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Therefore, \"tf.keras.initializers.VarianceScaling(scale=1.0, mode=\"fan_in\", distribution=\"truncated_normal\", seed=None)\" kernel initializer is used further on"
      ],
      "metadata": {
        "id": "n--GWe0euIqH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Padding"
      ],
      "metadata": {
        "id": "ei1wIwrbuIqH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "paddings = ['valid','same']\n",
        "initializer = tf.keras.initializers.VarianceScaling(scale=1.0, mode=\"fan_in\", distribution=\"truncated_normal\", seed=None)\n",
        "batch_size = 50\n",
        "dropout = 0.2\n",
        "test_acc=[]\n",
        "for padding in paddings:\n",
        "    print('padding : ',padding)\n",
        "    model = models.Sequential()\n",
        "\n",
        "    model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3),kernel_initializer = initializer))\n",
        "    model.add(layers.Conv2D(32, (3, 3), activation='relu',kernel_initializer = initializer))\n",
        "    model.add(Dropout(dropout))\n",
        "    model.add(layers.MaxPooling2D((2, 2),padding = padding))\n",
        "\n",
        "    model.add(layers.Conv2D(64, (3, 3), activation='relu',kernel_initializer = initializer))\n",
        "    model.add(layers.Conv2D(64, (3, 3), activation='relu',kernel_initializer = initializer))\n",
        "    model.add(Dropout(dropout))\n",
        "    model.add(layers.MaxPooling2D((2, 2),padding = padding))\n",
        "\n",
        "    model.add(layers.Conv2D(128, (3, 3), activation='relu',kernel_initializer = initializer))\n",
        "    model.add(layers.Conv2D(128, (3, 3), activation='relu',kernel_initializer = initializer))\n",
        "    model.add(Dropout(dropout))\n",
        "    model.add(layers.MaxPooling2D((2, 2),padding = padding))\n",
        "\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(32, activation='relu',kernel_initializer = initializer))\n",
        "    model.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "    # model.summary()\n",
        "\n",
        "    model.compile(optimizer='adam',\n",
        "                loss='sparse_categorical_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "    hist = model.fit(X_train, y_train, epochs=10,batch_size=batch_size,validation_data = (X_val, y_val))\n",
        "    loss,accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
        "    test_acc.append(accuracy)"
      ],
      "metadata": {
        "id": "-uxFBkTwuIqH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(20,10))\n",
        "plt.bar(paddings, test_acc)\n",
        "plt.xlabel('Paddings')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Paddings Decision')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Amu3PibquIqI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Therefore, padding is set to \"same\" further on."
      ],
      "metadata": {
        "id": "jywHV7wMuIqI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Neurons\n"
      ],
      "metadata": {
        "id": "2XG3cRmpuIqI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "neurons = [[32,64,64,64,128,128,32],\n",
        "           [32,32,64,64,128,256,256],\n",
        "           [32,64,128,256,256,256,512],\n",
        "           [32,64,64,64,128,128,256],\n",
        "           [64,64,128,128,256,256,32]]\n",
        "padding = \"same\"\n",
        "initializer = tf.keras.initializers.VarianceScaling(scale=1.0, mode=\"fan_in\", distribution=\"truncated_normal\", seed=None)\n",
        "batch_size = 50\n",
        "dropout = 0.2\n",
        "test_acc=[]\n",
        "for neuron in neurons:\n",
        "    print('neuron : ',neuron)\n",
        "    model = models.Sequential()\n",
        "\n",
        "    model.add(layers.Conv2D(neuron[0], (3, 3), activation='relu', input_shape=(32, 32, 3),kernel_initializer = initializer))\n",
        "    model.add(layers.Conv2D(neuron[1], (3, 3), activation='relu',kernel_initializer = initializer))\n",
        "    model.add(Dropout(dropout))\n",
        "    model.add(layers.MaxPooling2D((2, 2),padding = padding))\n",
        "\n",
        "    model.add(layers.Conv2D(neuron[2], (3, 3), activation='relu',kernel_initializer = initializer))\n",
        "    model.add(layers.Conv2D(neuron[3], (3, 3), activation='relu',kernel_initializer = initializer))\n",
        "    model.add(Dropout(dropout))\n",
        "    model.add(layers.MaxPooling2D((2, 2),padding = padding))\n",
        "\n",
        "    model.add(layers.Conv2D(neuron[4], (3, 3), activation='relu',kernel_initializer = initializer))\n",
        "    model.add(layers.Conv2D(neuron[5], (3, 3), activation='relu',kernel_initializer = initializer))\n",
        "    model.add(Dropout(dropout))\n",
        "    model.add(layers.MaxPooling2D((2, 2),padding = padding))\n",
        "\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(neuron[6], activation='relu',kernel_initializer = initializer))\n",
        "    model.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "    # model.summary()\n",
        "\n",
        "    model.compile(optimizer='adam',\n",
        "                loss='sparse_categorical_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "    hist = model.fit(X_train, y_train, epochs=10,batch_size=batch_size,validation_data = (X_val, y_val))\n",
        "    loss,accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
        "    test_acc.append(accuracy)"
      ],
      "metadata": {
        "id": "NA3y0Hr_uIqJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(20,10))\n",
        "plt.plot(test_acc)\n",
        "plt.xlabel('Neurons')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Neurons Decision')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Toz7z7aYuIqJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Therefore, neurons for each layer is set to [32,64,128,32] further on."
      ],
      "metadata": {
        "id": "1XHWu32-uIqK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Epochs"
      ],
      "metadata": {
        "id": "s4BmplFQuIqK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs=[10,20,50,100,200]\n",
        "neuron = [32,64,128,32]\n",
        "padding = \"same\"\n",
        "initializer = tf.keras.initializers.VarianceScaling(scale=1.0, mode=\"fan_in\", distribution=\"truncated_normal\", seed=None)\n",
        "batch_size = 50\n",
        "dropout = 0.2\n",
        "test_acc=[]\n",
        "for epoch in epochs:\n",
        "    print('epoch : ',epoch)\n",
        "    model = models.Sequential()\n",
        "\n",
        "    model.add(layers.Conv2D(neuron[0], (3, 3), activation='relu', input_shape=(32, 32, 3),kernel_initializer = initializer))\n",
        "    model.add(Dropout(dropout))\n",
        "    model.add(layers.MaxPooling2D((2, 2),padding = padding))\n",
        "\n",
        "    model.add(layers.Conv2D(neuron[1], (3, 3), activation='relu',kernel_initializer = initializer))\n",
        "    model.add(Dropout(dropout))\n",
        "    model.add(layers.MaxPooling2D((2, 2),padding = padding))\n",
        "\n",
        "    model.add(layers.Conv2D(neuron[2], (3, 3), activation='relu',kernel_initializer = initializer))\n",
        "    model.add(Dropout(dropout))\n",
        "    model.add(layers.MaxPooling2D((2, 2),padding = padding))\n",
        "\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(neuron[3], activation='relu',kernel_initializer = initializer))\n",
        "    model.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "    # model.summary()\n",
        "\n",
        "    model.compile(optimizer='adam',\n",
        "                loss='sparse_categorical_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "    hist = model.fit(X_train, y_train, epochs=epoch,batch_size=batch_size,validation_data = (X_val, y_val))\n",
        "    score, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
        "    test_acc.append(accuracy)"
      ],
      "metadata": {
        "id": "dq9ozn6ZuIqK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(20,10))\n",
        "plt.plot(epochs, test_acc)\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Epochs Decision')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "print('Best Performance : ',max(test_acc))"
      ],
      "metadata": {
        "id": "UM1wk8GZuIqK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train, Val accuracy of the model with best performance(from above)"
      ],
      "metadata": {
        "id": "gDVqMf_0Kyft"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(20,10))\n",
        "plt.plot(hist.history['accuracy'],label='train_accuracy')\n",
        "plt.plot(hist.history['val_accuracy'],label='val_accuracy')\n",
        "plt.plot([accuracy]*100,label='test_accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Complicated CNN')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "print('Best Performance : ',max(test_acc))"
      ],
      "metadata": {
        "id": "_8fcEZN5KD2-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Changing Loss Function"
      ],
      "metadata": {
        "id": "6vYP7nu5GoFR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs=100\n",
        "neuron = [32,64,128,32]\n",
        "padding = \"same\"\n",
        "initializer = tf.keras.initializers.HeUniform()\n",
        "batch_size = 50\n",
        "dropout = 0.2\n",
        "\n",
        "#model\n",
        "\n",
        "model = models.Sequential()\n",
        "\n",
        "model.add(layers.Conv2D(neuron[0], (3, 3), activation='relu', input_shape=(32, 32, 3),kernel_initializer = initializer))\n",
        "model.add(layers.Conv2D(neuron[1], (3, 3), activation='relu',kernel_initializer = initializer))\n",
        "model.add(Dropout(dropout))\n",
        "model.add(layers.MaxPooling2D((2, 2),padding = padding))\n",
        "\n",
        "model.add(layers.Conv2D(neuron[1], (3, 3), activation='relu',kernel_initializer = initializer))\n",
        "model.add(layers.Conv2D(neuron[1], (3, 3), activation='relu',kernel_initializer = initializer))\n",
        "model.add(Dropout(dropout))\n",
        "model.add(layers.MaxPooling2D((2, 2),padding = padding))\n",
        "\n",
        "model.add(layers.Conv2D(neuron[2], (3, 3), activation='relu',kernel_initializer = initializer))\n",
        "model.add(layers.Conv2D(neuron[2], (3, 3), activation='relu',kernel_initializer = initializer))\n",
        "model.add(Dropout(dropout))\n",
        "model.add(layers.MaxPooling2D((2, 2),padding = padding))\n",
        "\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(neuron[3], activation='relu',kernel_initializer = initializer))\n",
        "model.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "# model.summary()\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "            loss='sparse_categorical_crossentropy',\n",
        "            metrics=['accuracy'])\n",
        "\n",
        "hist = model.fit(X_train, y_train, epochs=epochs,batch_size=batch_size,validation_data = (X_val, y_val))\n",
        "score, accuracy = model.evaluate(X_test, y_test, verbose=0)"
      ],
      "metadata": {
        "id": "szQRs_JKGx85"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}